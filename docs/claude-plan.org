#+TITLE: MCP Document Knowledge Base - Architectural Plan
#+AUTHOR: Christian Romney
#+DATE: 2025-07-08
#+STARTUP: overview
#+OPTIONS: toc:2 num:nil
#+PROPERTY: header-args :mkdirp yes

* Overview

This document outlines the simplified architectural plan for implementing a Clojure-based MCP (Model Context Protocol) server that provides semantic search capabilities for Emacs org-mode notes. The system integrates with local Ollama embedding models and a Qdrant vector database to enable intelligent knowledge retrieval for tool-capable LLMs.

* System Goals

** Primary Use Cases
1. *Semantic Search*: Find notes based on semantic similarity, returning document fragments with metadata including related notes, file paths, and timestamps
2. *Document Retrieval*: Return complete note documents and their metadata for LLM consumption
3. *LLM Integration*: Expose search and retrieval capabilities via MCP for summarization, citation, and research
4. *Automatic Knowledge Management*: Sync knowledge base with file system changes
5. *Local Privacy-First Operation*: Run entirely locally without external dependencies

** Technical Requirements
- Written in Clojure for power, elegance, and simplicity
- Local Qdrant vector database for semantic search
- MCP server exposing JSON-RPC 2.0 over HTTP with Server-Sent Events
- Integration with local Ollama embedding models
- File system watching for automatic updates
- Org-mode document parsing and processing
- Focus on two core operations: search and retrieval

* Architecture Overview

#+BEGIN_SRC mermaid :file tangle/claude-plan-architecture.png :exports both
graph TB
    subgraph "File System"
        A[Org-mode Notes] -->|File Changes| B[File Watcher]
    end
    
    subgraph "MCP Document KB System"
        B --> C[Document Ingestion]
        C --> D[Document Parser]
        D --> E[Text Chunker]
        E --> F[Embedding Generator]
        F --> G[Qdrant Vector DB]
        
        H[MCP Server] --> I[JSON-RPC Handler]
        I --> J[Search Service]
        J --> G
        J --> K[Document Store]
    end
    
    subgraph "External Services"
        F --> L[Ollama Embedding API]
    end
    
    subgraph "Client Applications"
        M[LLM Tools] --> H
        N[IDE Extensions] --> H
    end
#+END_SRC

#+RESULTS:
[[file:tangle/claude-plan-architecture.png]]

* Core Components

** 1. Document Ingestion
*Purpose*: Process org-mode files and extract searchable content

*Components*:
- *File Watcher*: Monitor directory for changes using Java NIO WatchService
- *Document Parser*: Parse org-mode syntax and extract metadata
- *Text Chunker*: Split documents into semantic chunks for embedding
- *Embedding Generator*: Generate vectors using local Ollama models

*Key Operations*:
- =ingest-file=: Process a single org-mode file
- =ingest-directory=: Recursively process a directory of files
- =update-file=: Handle file modifications
- =delete-file=: Remove file from index

** 2. MCP Server
*Purpose*: Expose knowledge base capabilities via standardized MCP protocol

*Components*:
- *JSON-RPC Handler*: Process MCP requests/responses
- *Tool Registry*: Register available MCP tools
- *Transport Layer*: HTTP server with Server-Sent Events support

*MCP Tools*:
- =search-notes=: Semantic search returning document fragments with metadata
- =retrieve-note=: Return complete note document and metadata

** 3. Search Service
*Purpose*: Provide semantic search and document retrieval

*Components*:
- *Query Processor*: Parse and normalize search queries
- *Vector Search*: Perform similarity search in Qdrant
- *Result Builder*: Construct responses with fragments, metadata, and related notes
- *Document Retriever*: Fetch complete documents by identifier

*Operations*:
- *Semantic Search*: Find conceptually related content with metadata
- *Document Retrieval*: Return complete note documents
- *Related Note Discovery*: Identify semantically similar notes

* Data Flow Architecture

** Document Ingestion Flow
1. *File Detection*: File watcher detects changes in org-mode files
2. *Content Parsing*: Extract text content and metadata from org-mode syntax
3. *Chunk Generation*: Split content into semantic chunks (paragraphs, sections)
4. *Embedding Creation*: Generate vectors using Ollama embedding models
5. *Vector Storage*: Store embeddings and metadata in Qdrant with indexing
6. *Graph Updates*: Update knowledge graph with new concepts and relationships

** Search Query Flow
1. *Query Reception*: MCP server receives search request via JSON-RPC
2. *Query Processing*: Parse and normalize search parameters
3. *Vector Generation*: Create embedding for search query
4. *Similarity Search*: Query Qdrant for similar vectors
5. *Result Building*: Construct response with document fragments, metadata, and related notes
6. *Response Delivery*: Return formatted results via MCP protocol

** Document Retrieval Flow
1. *Retrieval Request*: MCP server receives document retrieval request
2. *Document Lookup*: Find document by identifier in document store
3. *Metadata Assembly*: Gather file path, timestamps, and related notes
4. *Response Delivery*: Return complete document with metadata

* Implementation Phases

** Phase 1: Foundation (Weeks 1-2)
- Set up core Clojure project structure
- Implement basic org-mode parsing and chunking
- Establish Qdrant connection and basic vector operations
- Build file watching infrastructure
- Create document metadata extraction

** Phase 2: Core Functionality (Weeks 3-4)
- Implement Ollama integration for embeddings
- Create document ingestion pipeline with automatic updates
- Build search service with semantic similarity
- Develop MCP server framework with JSON-RPC 2.0
- Implement =search-notes= and =retrieve-note= MCP tools

** Phase 3: Integration & Polish (Weeks 5-6)
- Add related notes discovery and metadata enrichment
- Optimize performance and indexing strategies
- Add comprehensive error handling and recovery
- Create configuration management with sensible defaults
- Build monitoring, logging, and comprehensive test coverage

* Key Design Decisions

** 1. Chunking Strategy
- *Approach*: Semantic chunking based on org-mode structure
- *Rationale*: Preserve document hierarchy and context
- *Implementation*: Split on headers, paragraphs, and logical sections

** 2. Embedding Model Selection
- *Approach*: Support multiple Ollama models with configuration
- *Default*: =mxbai-embed-large= for high-quality embeddings
- *Rationale*: Local models provide privacy and cost control

** 3. Vector Search Strategy
- *Approach*: Qdrant for production-grade vector search
- *Configuration*: Configurable similarity thresholds and result limits
- *Optimization*: Index tuning for document size and search patterns

** 4. MCP Protocol Implementation
- *Transport*: HTTP with Server-Sent Events for streaming
- *Format*: JSON-RPC 2.0 for standardized communication
- *Tools*: Rich set of search and analysis tools

* Configuration Management

** Environment Variables
- =QDRANT_URL=: Qdrant server connection string
- =OLLAMA_URL=: Ollama API endpoint
- =NOTES_DIR=: Directory containing org-mode files
- =EMBEDDING_MODEL=: Ollama embedding model name
- =MCP_PORT=: MCP server port
- =LOG_LEVEL=: Logging verbosity

** Configuration Files
- =config.edn=: Main configuration with defaults
- =models.edn=: Embedding model configurations
- =search.edn=: Search engine parameters
- =graph.edn=: Knowledge graph settings

* Testing Strategy

** Unit Tests
- Document parsing and chunking
- Vector operations and similarity search
- MCP protocol handling
- Knowledge graph algorithms

** Integration Tests
- End-to-end document ingestion
- Search query processing
- MCP tool execution
- File watching and updates

** Performance Tests
- Large document collection handling
- Search response times
- Memory usage optimization
- Concurrent request handling

* Monitoring and Observability

** Metrics
- Document ingestion rates
- Search query latency
- Vector database performance
- MCP server response times

** Logging
- Structured logging with context
- Error tracking and alerting
- Performance monitoring
- Audit trail for data changes

* Security Considerations

** Data Privacy
- All processing occurs locally
- No external API calls for sensitive content
- Configurable data retention policies
- Secure file access controls

** API Security
- Authentication for MCP connections
- Rate limiting for API endpoints
- Input validation and sanitization
- Secure configuration management

* Future Enhancements

** Advanced Features
- Multi-modal document support (images, PDFs)
- Real-time collaborative editing integration
- Advanced knowledge graph visualization
- Machine learning-powered concept extraction

** Performance Optimizations
- Distributed vector search
- Incremental indexing strategies
- Caching layers for frequent queries
- Parallel processing pipelines

** Integration Possibilities
- Emacs org-roam integration
- VS Code extension support
- Jupyter notebook integration
- Web-based knowledge explorer

* Success Metrics

** Functional Metrics
- Search relevance accuracy > 85%
- Document ingestion speed > 100 docs/minute
- Search response time < 500ms
- Knowledge graph completeness > 90%

** Operational Metrics
- System uptime > 99.9%
- Error rate < 0.1%
- Memory usage < 2GB for 10K documents
- CPU usage < 50% under normal load

* Risks and Mitigations

** Technical Risks
- *Qdrant dependency*: Mitigate with containerization and backup strategies
- *Ollama model availability*: Support multiple embedding models
- *Memory usage with large corpora*: Implement streaming and pagination
- *Search result quality*: Continuous evaluation and model tuning

** Operational Risks
- *Configuration complexity*: Provide sensible defaults and validation
- *File system changes*: Robust error handling and recovery
- *Network connectivity*: Graceful degradation for offline operation
- *Data corruption*: Regular backups and integrity checks

This architectural plan provides a comprehensive foundation for implementing the MCP document knowledge base system while maintaining flexibility for future enhancements and ensuring robust operation in local environments.
