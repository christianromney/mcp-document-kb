#+TITLE: MCP-Document-KB Architectural Plan
#+AUTHOR: Christian Romney
#+DATE: 2025-07-08
#+STARTUP: overview
#+OPTIONS: toc:2 num:nil

* Introduction
This document outlines the high-level architecture for the MCP-Document-KB system, providing a local, semantic search knowledgebase accessible via the Model Context Protocol (MCP).

* Goals
  - Implement a local semantic search knowledgebase.
  - Provide access to the knowledgebase via MCP.

* Components

**1. Note Ingestion & Processing**
   - Input: Org-mode files from a specified directory.
   - Processing: Extract text content and generate embeddings (using Ollama).
   - Output: Data suitable for indexing in Qdrant.

**2. Vector Database (Qdrant)**
   - Stores document embeddings and associated metadata.
   - Provides efficient similarity search capabilities.

**3. MCP Server**
   - API: JSON-RPC 2.0 for handling MCP requests.
   - Search Endpoint: Queries Qdrant, retrieves related notes and metadata.
   - Streaming: Utilizes Server-Sent Events (SSE) to return results to LLMs.

**4. LLM Integration (Ollama)**
   - Embedding Models: Local embedding models for generating document embeddings.
   - LLMs: Local LLMs (e.g., gemma3n) for utilizing the knowledgebase.

**5. Automation**
   - File System Monitoring: Watches the source directory for changes (additions, modifications, deletions).
   - Index Management: Automatically updates the Qdrant index based on file system changes.

* Technology Stack

  - Language: Clojure
  - Database: Qdrant
  - LLMs: Ollama (gemma3n, embedding models)
  - API: JSON-RPC 2.0, Server-Sent Events (SSE)
  - Documentation: Org-mode, Mermaid diagrams.

* Workflow

  1. Note changes trigger ingestion and processing.
  2. Processed notes are added/updated in Qdrant.
  3. An LLM sends an MCP search request.
  4. The MCP server queries Qdrant.
  5. The MCP server streams results (notes, metadata) to the LLM via SSE.
